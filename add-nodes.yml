#!/usr/bin/env ansible-playbook
#
# (c) 2017 DataNexus Inc.  All Rights Reserved
---
# Build our spark and spark_master host groups
- name: Create spark and spark_master host groups
  hosts: localhost
  gather_facts: no
  tasks:
    # if we're using dynamic provisioning; build the host groups from the
    # meta-data associated with the matching nodes in the selected cloud
    - block:
      # load the 'local variables file', if one was defined, to get any variables
      # we might need from that file when constructing our host groups
      - name: Load local variables file
        include_vars:
          file: "{{local_vars_file}}"
        when: not (local_vars_file is undefined or local_vars_file is none or local_vars_file | trim == '')
      # then, build our host groups (spark_master, spark, and zookeeper)
      - include_role:
          name: build-app-host-groups
        vars:
          host_group_list:
            - { name: spark, role: master }
            - { name: spark }
            - name: zookeeper
      when: cloud is defined and (cloud == 'aws' or cloud == 'osp')

# Collect some Zookeeper related facts
- name: Gather facts from Zookeeper host group (if defined)
  hosts: zookeeper
  tasks: []

# And gather facts from the master nodes
- name: Install/configure servers (master nodes)
  hosts: spark_master
  tasks: []

# Then, deploy Spark to the new target nodes (those that don't have a
# spark service configured on them already) and configure those nodes to
# join the existing cluster
- name: Install/configure servers (worker nodes)
  hosts: spark
  gather_facts: no
  vars_files:
    - vars/spark.yml
  vars:
    - combined_package_list: "{{ (default_packages|default([])) | union(spark_package_list) | union((install_packages_by_tag|default({})).spark|default([])) }}"
    - zookeeper_nodes: "{{groups['zookeeper']}}"
    - spark_master_nodes: "{{groups['spark_master']}}"
  pre_tasks:
    # first, initialize the play by loading any `local_vars_file` that may have
    # been passed in, restarting the network on the target nodes (if desired),
    # and determining the `data_iface` and `api_iface` values from the input
    # `iface_description_array` (if one was passed in)
    - include_role:
        name: initialize-play
    # and now that we know the name of our `data_iface`, we can construct the
    # list of zk_nodes (the data_iface IP addresses of our zookeeper_nodes)
    - set_fact:
        zk_nodes: "{{(zookeeper_nodes | default([])) | map('extract', hostvars, [('ansible_' + data_iface), 'ipv4', 'address']) | list}}"
  # now that we have all of the facts we need, add the new (worker) nodes to
  # the cluster
  roles:
    - role: add-nodes
      service_deployed: spark-worker
